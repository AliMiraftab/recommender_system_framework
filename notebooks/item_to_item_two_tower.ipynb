{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ali/anaconda3/envs/recsys_framework/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pprint\n",
    "import tempfile\n",
    "\n",
    "from typing import Dict, Text\n",
    "\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import tensorflow_datasets as tfds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow_recommenders as tfrs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-01-24 16:53:20.532160: W tensorflow/tsl/platform/cloud/google_auth_provider.cc:184] All attempts to get a Google authentication bearer token failed, returning an empty token. Retrieving token from files failed with \"NOT_FOUND: Could not locate the credentials file.\". Retrieving token from GCE failed with \"INTERNAL: Couldn't parse JSON response from OAuth server.\".\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1mDownloading and preparing dataset 4.70 MiB (download: 4.70 MiB, generated: 32.41 MiB, total: 37.10 MiB) to /Users/ali/tensorflow_datasets/movielens/100k-ratings/0.1.1...\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Dl Completed...: 0 url [00:00, ? url/s]\n",
      "Dl Completed...:   0%|          | 0/1 [00:00<?, ? url/s]\n",
      "Dl Completed...:   0%|          | 0/1 [00:00<?, ? url/s]\n",
      "Dl Completed...:   0%|          | 0/1 [00:00<?, ? url/s]\n",
      "Dl Completed...:   0%|          | 0/1 [00:00<?, ? url/s]\n",
      "Dl Completed...:   0%|          | 0/1 [00:00<?, ? url/s]\n",
      "Dl Completed...:   0%|          | 0/1 [00:00<?, ? url/s]\n",
      "Dl Completed...: 100%|██████████| 1/1 [00:00<00:00,  1.09 url/s]\n",
      "Dl Completed...: 100%|██████████| 1/1 [00:00<00:00,  1.08 url/s]\n",
      "Dl Completed...: 100%|██████████| 1/1 [00:00<00:00,  1.07 url/s]\n",
      "Dl Completed...: 100%|██████████| 1/1 [00:00<00:00,  1.07 url/s]\n",
      "Dl Completed...: 100%|██████████| 1/1 [00:00<00:00,  1.06 url/s]\n",
      "Dl Completed...: 100%|██████████| 1/1 [00:00<00:00,  1.05 url/s]\n",
      "Dl Completed...: 100%|██████████| 1/1 [00:00<00:00,  1.05 url/s]\n",
      "Dl Completed...: 100%|██████████| 1/1 [00:00<00:00,  1.05 url/s]\n",
      "Dl Completed...: 100%|██████████| 1/1 [00:00<00:00,  1.05 url/s]\n",
      "Dl Completed...: 100%|██████████| 1/1 [00:00<00:00,  1.05 url/s]\n",
      "Dl Completed...: 100%|██████████| 1/1 [00:00<00:00,  1.04 url/s]\n",
      "Dl Completed...: 100%|██████████| 1/1 [00:00<00:00,  1.03 url/s]\n",
      "Dl Completed...: 100%|██████████| 1/1 [00:00<00:00,  1.02 url/s]\n",
      "Dl Completed...: 100%|██████████| 1/1 [00:00<00:00,  1.01 url/s]\n",
      "Dl Completed...: 100%|██████████| 1/1 [00:00<00:00,  1.00 url/s]\n",
      "Dl Completed...: 100%|██████████| 1/1 [00:01<00:00,  1.00s/ url]\n",
      "Dl Completed...: 100%|██████████| 1/1 [00:01<00:00,  1.01s/ url]\n",
      "Dl Completed...: 100%|██████████| 1/1 [00:01<00:00,  1.02s/ url]\n",
      "Dl Completed...: 100%|██████████| 1/1 [00:01<00:00,  1.02s/ url]\n",
      "Dl Completed...: 100%|██████████| 1/1 [00:01<00:00,  1.03s/ url]\n",
      "Dl Completed...: 100%|██████████| 1/1 [00:01<00:00,  1.03s/ url]\n",
      "Dl Completed...: 100%|██████████| 1/1 [00:01<00:00,  1.04s/ url]\n",
      "Dl Completed...: 100%|██████████| 1/1 [00:01<00:00,  1.05s/ url]\n",
      "Dl Completed...: 100%|██████████| 1/1 [00:01<00:00,  1.05s/ url]\n",
      "\u001b[A\n",
      "Dl Completed...: 100%|██████████| 1/1 [00:01<00:00,  1.05s/ url]\n",
      "Dl Completed...: 100%|██████████| 1/1 [00:01<00:00,  1.06s/ url]\n",
      "Dl Completed...: 100%|██████████| 1/1 [00:01<00:00,  1.06s/ url]\n",
      "Dl Completed...: 100%|██████████| 1/1 [00:01<00:00,  1.06s/ url]\n",
      "Dl Completed...: 100%|██████████| 1/1 [00:01<00:00,  1.06s/ url]\n",
      "Dl Completed...: 100%|██████████| 1/1 [00:01<00:00,  1.06s/ url]\n",
      "Dl Completed...: 100%|██████████| 1/1 [00:01<00:00,  1.06s/ url]\n",
      "Dl Completed...: 100%|██████████| 1/1 [00:01<00:00,  1.06s/ url]\n",
      "Dl Completed...: 100%|██████████| 1/1 [00:01<00:00,  1.06s/ url]\n",
      "Dl Completed...: 100%|██████████| 1/1 [00:01<00:00,  1.07s/ url]\n",
      "Dl Completed...: 100%|██████████| 1/1 [00:01<00:00,  1.07s/ url]\n",
      "Dl Completed...: 100%|██████████| 1/1 [00:01<00:00,  1.07s/ url]\n",
      "Dl Completed...: 100%|██████████| 1/1 [00:01<00:00,  1.07s/ url]\n",
      "Dl Completed...: 100%|██████████| 1/1 [00:01<00:00,  1.07s/ url]\n",
      "Dl Completed...: 100%|██████████| 1/1 [00:01<00:00,  1.07s/ url]\n",
      "Dl Completed...: 100%|██████████| 1/1 [00:01<00:00,  1.07s/ url]\n",
      "Dl Completed...: 100%|██████████| 1/1 [00:01<00:00,  1.07s/ url]\n",
      "Dl Completed...: 100%|██████████| 1/1 [00:01<00:00,  1.07s/ url]\n",
      "Dl Completed...: 100%|██████████| 1/1 [00:01<00:00,  1.08s/ url]\n",
      "Dl Completed...: 100%|██████████| 1/1 [00:01<00:00,  1.08s/ url]\n",
      "Dl Completed...: 100%|██████████| 1/1 [00:01<00:00,  1.08s/ url]\n",
      "Dl Completed...: 100%|██████████| 1/1 [00:01<00:00,  1.08s/ url]\n",
      "Dl Completed...: 100%|██████████| 1/1 [00:01<00:00,  1.08s/ url]\n",
      "Extraction completed...: 100%|██████████| 23/23 [00:01<00:00, 21.30 file/s]\n",
      "Dl Size...: 100%|██████████| 4/4 [00:01<00:00,  3.70 MiB/s]\n",
      "Dl Completed...: 100%|██████████| 1/1 [00:01<00:00,  1.08s/ url]\n",
      "                                                                        \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1mDataset movielens downloaded and prepared to /Users/ali/tensorflow_datasets/movielens/100k-ratings/0.1.1. Subsequent calls will reuse this data.\u001b[0m\n",
      "\u001b[1mDownloading and preparing dataset 4.70 MiB (download: 4.70 MiB, generated: 150.35 KiB, total: 4.84 MiB) to /Users/ali/tensorflow_datasets/movielens/100k-movies/0.1.1...\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Dl Completed...: 0 url [00:00, ? url/s]\n",
      "Dl Completed...:   0%|          | 0/1 [00:00<?, ? url/s]\n",
      "Dl Completed...: 100%|██████████| 1/1 [00:00<00:00, 144.89 url/s]\n",
      "Dl Completed...: 100%|██████████| 1/1 [00:00<00:00, 113.92 url/s]\n",
      "Dl Completed...: 100%|██████████| 1/1 [00:00<00:00, 92.78 url/s] \n",
      "Extraction completed...: 0 file [00:00, ? file/s]\n",
      "Dl Size...: 100%|██████████| 4924029/4924029 [00:00<00:00, 363095543.79 MiB/s]\n",
      "Dl Completed...: 100%|██████████| 1/1 [00:00<00:00, 64.34 url/s]\n",
      "                                                                        "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1mDataset movielens downloaded and prepared to /Users/ali/tensorflow_datasets/movielens/100k-movies/0.1.1. Subsequent calls will reuse this data.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r"
     ]
    }
   ],
   "source": [
    "# Ratings data.\n",
    "ratings = tfds.load(\"movielens/100k-ratings\", split=\"train\")\n",
    "# Features of all the available movies.\n",
    "movies = tfds.load(\"movielens/100k-movies\", split=\"train\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'bucketized_user_age': 45.0,\n",
      " 'movie_genres': array([7]),\n",
      " 'movie_id': b'357',\n",
      " 'movie_title': b\"One Flew Over the Cuckoo's Nest (1975)\",\n",
      " 'raw_user_age': 46.0,\n",
      " 'timestamp': 879024327,\n",
      " 'user_gender': True,\n",
      " 'user_id': b'138',\n",
      " 'user_occupation_label': 4,\n",
      " 'user_occupation_text': b'doctor',\n",
      " 'user_rating': 4.0,\n",
      " 'user_zip_code': b'53211'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-01-24 16:55:20.376349: W tensorflow/core/kernels/data/cache_dataset_ops.cc:854] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n"
     ]
    }
   ],
   "source": [
    "for x in ratings.take(1).as_numpy_iterator():\n",
    "  pprint.pprint(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'movie_genres': array([4]),\n",
      " 'movie_id': b'1681',\n",
      " 'movie_title': b'You So Crazy (1994)'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-01-24 16:56:11.533161: W tensorflow/core/kernels/data/cache_dataset_ops.cc:854] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n"
     ]
    }
   ],
   "source": [
    "for x in movies.take(1).as_numpy_iterator():\n",
    "  pprint.pprint(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "recsys_framework",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
